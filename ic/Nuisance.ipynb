{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import beanmachine.ppl as bm\n",
    "import beanmachine.ppl.experimental.inference_compilation.ic_infer as ic_infer\n",
    "from beanmachine.ppl.model.statistical_model import StatisticalModel\n",
    "from beanmachine.ppl.model.utils import Mode\n",
    "\n",
    "import torch\n",
    "import torch.distributions as dist\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3464a525323e4801bd65e62f570d8d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=63.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor([46.1922], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7cba1e1abd6440ca1d73320ef66adbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Samples collected', style=ProgressStyle(description_widthâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class NuisanceParameterModel:\n",
    "    @bm.random_variable\n",
    "    def x(self):\n",
    "        return dist.Normal(0, 1)\n",
    "    \n",
    "    @bm.random_variable\n",
    "    def nuisance(self, i):\n",
    "        return dist.Normal(0, 1)\n",
    "    \n",
    "    @bm.random_variable\n",
    "    def y(self):\n",
    "        return dist.Normal(0, 1)\n",
    "    \n",
    "    @bm.random_variable\n",
    "    def noisy_sq_length(self):\n",
    "        return dist.Normal(self.x()**2 + self.y()**2, 0.01)\n",
    "    \n",
    "\n",
    "model = NuisanceParameterModel()\n",
    "ic = ic_infer.ICInference().compile(\n",
    "    [model.noisy_sq_length()],\n",
    "    num_worlds=1e3,\n",
    "    optimizer_func=lambda x: optim.Adam(x, lr=1e-3),\n",
    ")\n",
    "samples = ic.infer(\n",
    "    [model.x()],\n",
    "    {model.noisy_sq_length(): torch.tensor(1.0)},\n",
    "    num_samples=100,\n",
    "    num_chains=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg</th>\n",
       "      <th>std</th>\n",
       "      <th>2.5%</th>\n",
       "      <th>50%</th>\n",
       "      <th>97.5%</th>\n",
       "      <th>n_eff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x(&lt;__main__.NuisanceParameterModel object at 0x7f739623c3d0&gt;,)[]</th>\n",
       "      <td>0.066708</td>\n",
       "      <td>0.042006</td>\n",
       "      <td>0.019782</td>\n",
       "      <td>0.076276</td>\n",
       "      <td>0.126133</td>\n",
       "      <td>5.504583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         avg       std  \\\n",
       "x(<__main__.NuisanceParameterModel object at 0x...  0.066708  0.042006   \n",
       "\n",
       "                                                        2.5%       50%  \\\n",
       "x(<__main__.NuisanceParameterModel object at 0x...  0.019782  0.076276   \n",
       "\n",
       "                                                       97.5%     n_eff  \n",
       "x(<__main__.NuisanceParameterModel object at 0x...  0.126133  5.504583  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm.Diagnostics(samples).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_params = 0\n",
    "for pg in ic._optimizer.param_groups:\n",
    "    for p in pg['params']:\n",
    "        num_params += p.numel()\n",
    "num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new inference network...\n",
      "Observable noisy_sq_length_lik: reshape not specified, using shape torch.Size([]).\n",
      "Observable noisy_sq_length_lik: using embedding dim torch.Size([4]).\n",
      "Observable noisy_sq_length_lik: observe embedding not specified, using the default FEEDFORWARD.\n",
      "Observable noisy_sq_length_lik: embedding depth not specified, using the default 2.\n",
      "Observe embedding dimension: 4\n",
      "Train. time | Epoch| Trace     | Init. loss| Min. loss | Curr. loss| T.since min | Learn.rate| Traces/sec\n",
      "New layers, address: 16__forward__x__Normal__1, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__1, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__2, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__3, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__4, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__5, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__6, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__7, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__8, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__9, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__10, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__11, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__12, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__13, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__14, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__15, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__16, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__17, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__18, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__19, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__20, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__21, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__22, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__23, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__24, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__25, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__26, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__27, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__28, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__29, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__30, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__31, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__32, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__33, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__34, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__35, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__36, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__37, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__38, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__39, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__40, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__41, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__42, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__43, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__44, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__45, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__46, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__47, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__48, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__49, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__50, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__51, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__52, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__53, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__54, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__55, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__56, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__57, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__58, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__59, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__60, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__61, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__62, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__63, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__64, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__65, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__66, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__67, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__68, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__69, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__70, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__71, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__72, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__73, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__74, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__75, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__76, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__77, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__78, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__79, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__80, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__81, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__82, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__83, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__84, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__85, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__86, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__87, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__88, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__89, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__90, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__91, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__92, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__93, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__94, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__95, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__96, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__97, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__98, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__99, distribution: Normal\n",
      "New layers, address: 24__forward__<listcomp>__?__Normal__100, distribution: Normal\n",
      "New layers, address: 54__forward__y__Normal__1, distribution: Normal\n",
      "Total addresses: 102, distribution types: 1, parameters: 16,384,042\n",
      "0d:00:00:43 | 1    | 960       | +1.45e+02 | +1.43e+02 | \u001b[32m+1.43e+02\u001b[0m | 0d:00:00:05 | +1.00e-03 | 21.6                               \n",
      "Stop condition reached. num_traces: 1000\n",
      "0d:00:00:46 | 1    | 1,024     | +1.45e+02 | \u001b[1m\u001b[32m+1.42e+02\u001b[0m | \u001b[1m\u001b[32m+1.42e+02\u001b[0m | \u001b[1m\u001b[32m0d:00:00:00\u001b[0m | +1.00e-03 | 21.3 \n"
     ]
    }
   ],
   "source": [
    "import pyprob\n",
    "import pyprob.distributions\n",
    "\n",
    "class NuisanceModel(pyprob.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='Nuisance parameters')\n",
    "\n",
    "    def forward(self):\n",
    "        x = pyprob.sample(pyprob.distributions.Normal(0, 1))\n",
    "        nuisance = [pyprob.sample(pyprob.distributions.Normal(0, 1)) for _ in range(100)]\n",
    "        y = pyprob.sample(pyprob.distributions.Normal(0, 1))\n",
    "\n",
    "        noisy_sq_length_lik = pyprob.distributions.Normal(x**2 + y**2, 0.01)\n",
    "\n",
    "        pyprob.observe(noisy_sq_length_lik, name='noisy_sq_length_lik')\n",
    "        return x\n",
    "    \n",
    "model = NuisanceModel()\n",
    "model.learn_inference_network(num_traces=int(1e3),\n",
    "                              observe_embeddings={'noisy_sq_length_lik' : {'dim' : 4}},\n",
    "                              inference_network=pyprob.InferenceNetwork.LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent  | Time remain.| Progress             | Trace   | Traces/sec\n",
      "0d:00:00:27 | 0d:00:00:00 | #################### | 100/100 | 3.64       \n"
     ]
    }
   ],
   "source": [
    "posterior = model.posterior_results(\n",
    "    num_traces=100, # the number of samples estimating the posterior\n",
    "    inference_engine=pyprob.InferenceEngine.IMPORTANCE_SAMPLING_WITH_INFERENCE_NETWORK, # specify which inference engine to use\n",
    "    observe={'noisy_sq_length_lik': 1.0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0485, dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior._effective_sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
