% !TeX root = thesis.tex
% (This file is included by thesis.tex; you do not latex it by itself.)

\begin{abstract}

    % The text of the abstract goes here.  If you need to use a \section
    % command you will need to use \section*, \subsection*, etc. so that
    % you don't get any numbering.  You probably won't be using any of
    % these commands in the abstract anyway.

    This dissertation considers a range of problems at the intersection of randomized methods
    and statistics. Initially in the first three chapters, we develop novel analyses to recent problems
    in experimental design, double descent, and random projections by using determinantal
    point processes (DPP).
    \Cref{ch:design} consider approximately optimal Bayesian experimental design
    using an adaptive row sampling algorithm based on DPPs and show that it provides
    good approximations. In \cref{ch:double_descent} an extension of the DPP-based design is analyzed in
    closed-form for the over-parameterized $n < d$ regime and predicts a double-descent phenomenon in
    linear regression which closely matches empirical experiments.
    In \cref{ch:projections} we isolate the part of the proof involving concentration
    of bilinear forms of matrix resolvents away from the DPP-based design in order to obtain bounds on
    expected projections $X_S^\dag X_S$ when $X_S = S X$ is obtained by sub-Gaussian sketching matrix $S$.

    In the later chapters we focus on probabilistic programming and developing theory and tools
    to automate statistical inference using randomized algorithms based on
    Monte Carlo Markoc chain (MCMC) and variational inference (VI).
    \Cref{ch:lic} considers parameterizing $q(x)$ by graph neural networks which condition each
    node on its Markov blanket. This reduces the conditioning sets for a node, resulting in improvements over
    \cite{le2017inference} and run-times which depend on sparsity in the graphical model rather than
    the length of execution traces.
    When the target $p(x)$ is both multivariate and heavy tailed, \cref{ch:ftvi}
    considers the problem of tail anisotropy through both a theoretical and practical perspective.
    However, we find in practice FTVI and other tail-adaptive approximations often have trouble optimizing
    the tail parameter. In \cref{ch:hta}, we consider addressing this issue during static analysis of a
    probabilistic program's source code.

\end{abstract}
